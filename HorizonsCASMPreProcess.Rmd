---
title: "R Notebook to preprocess water quality data for use with CASM, for Horizons"
output: html_notebook
---

Load libraries
```{r}
```

Some functions
```{r}


#Create scenario leach rate rasters from Horizon's Plan change 2 Table 14.2, from the raster of the Sub-management Zone-Land Use-LUC (and the look up table which #converts the class numbers to descriptions), and the "current" MPI-based leach rate raster

ScenarioLeachRateRaster <- function(CurrentLeachRateRaster = LeachRate, LUC_To_Leach_Table = LeachRateLimits, ZoneLanduseLUCRasterFile = ZoneLanduseLUCRasterFileName, ZoneLanduseLUCCode_To_ClassLUTFile = ZoneLanduseLUCCode_To_ClassLUTFileName, plan = "PC2", year = 20) {
  
  #Load the ZoneLanduseLUC raster and the look up table that relates the raster's codes to a combined-class name
  ZoneLanduseLUCRaster <- raster(file.path(GISDataDirectory,ZoneLanduseLUCRasterFile))
  ZoneLanduseLUC_LUT <- read.table(file.path(DataDirectory,ZoneLanduseLUCCode_To_ClassLUTFile),sep=",",header=TRUE)
  
  #Parse the Combined name into its constituent parts
  ZoneLanduseLUC_LUT$Zone <- as.factor(sub('-.*','',ZoneLanduseLUC_LUT$CombinedClassName))
  ZoneLanduseLUC_LUT$ZoneNo <- as.numeric(ZoneLanduseLUC_LUT$Zone)
  ZoneLanduseLUC_LUT$Landuse <- as.factor(sub('.*-(.*)-.*','\\1',ZoneLanduseLUC_LUT$CombinedClassName))
  ZoneLanduseLUC_LUT$LanduseNo <- as.numeric(ZoneLanduseLUC_LUT$Landuse)                                         
  ZoneLanduseLUC_LUT$LUC <- as.numeric(sub('.*-','',ZoneLanduseLUC_LUT$CombinedClassName))

  #reclasify ZoneLanduSeLUCRaster based on levels to the constituent parts
  LandUseRaster <- reclassify(ZoneLanduseLUCRaster,as.matrix(ZoneLanduseLUC_LUT[,c('ID','LanduseNo')]))
  SMZRaster <- reclassify(ZoneLanduseLUCRaster,as.matrix(ZoneLanduseLUC_LUT[,c('ID','ZoneNo')]))
  LUCRaster <- reclassify(ZoneLanduseLUCRaster,as.matrix(ZoneLanduseLUC_LUT[,c('ID','LUC')]))
  
  
  
  #Reclasify to Table 14.2 leach rates as though they applied everywhere
  LeachRateLUT <- matrix(ncol=2,c(1:8,t(LUC_To_Leach_Table[LUC_To_Leach_Table$Year == year & LUC_To_Leach_Table$Plan == plan,c(3:10)])))
  AreaWideScenarioLeachRates <- reclassify(LUCRaster, LeachRateLUT)

  #Turn the ZoneLanduseLUCRaster into an "intensive farming" mask, based on rules as to what constitutes intensive farming
  IntensiveFarmingMask <- !LandUseRaster %in% which(levels(ZoneLanduseLUC_LUT$Landuse) %in% c("Native Cover","Water Body"))
  
  #For the intensive farming areas find the Scenario leach rates, otherwise, keep using the MPI leach rates
  ScenarioLeachRate <- AreaWideScenarioLeachRates * IntensiveFarmingMask + CurrentLeachRateRaster * !IntensiveFarmingMask
  
  
  #Export a raster stack for exploration in QGIS
  ScenarioRasters <- raster::stack(x=list(Scenario=ScenarioLeachRate,ScenarioAll=AreaWideScenarioLeachRates,Mask=IntensiveFarmingMask,MPI=CurrentLeachRateRaster,LUC=LUCRaster,Landuse=LandUseRaster))
  writeRaster(ScenarioRasters,file.path(GISDataDirectory,"ScenarioLeachRasters.tif"),overwrite=TRUE)
  
  
  return(ScenarioLeachRate)
  }
```

Set directories and data file names
```{r}
#Set the project directory
ProjectDirectory <- "D:\\Projects\\LWP\\Horizons"       #Tim Kerr's Windows Home laptop

#Set the data directory
DataDirectory     <- file.path(ProjectDirectory, "Data")

#Set the GIS directory
GISDataDirectory  <- file.path(DataDirectory,"GIS")

#REC data is available from the MfE data service. See https://data.mfe.govt.nz/layer/51826-river-environment-classification-manawatu-2010/ and https://data.mfe.govt.nz/layer/51847-river-environment-classification-watershed-manawatu-2010/

REC_rivers <- "RECV2-Riverlines-Horizons"

REC_Catchments <- "RECV2-Watersheds-Horizons"

REC_MeanFlowFile <- "REC2MeanFlow.RData"  #This is an RData file

SubZones <-"Water_Management_Subzones_cleaned"

OutletReachNamesFile <- "OutletReachNames.csv" 

LanduseLUCShapefileName <- "Landuse_LUC Original"

SubZoneLanduseLUCShapeFileName <- "ZoneLanduseLUC/ZoneLanduseLUC.shp"

IrrigableLandShapeFileName <- "IrrigableLand/Irrigable-Horizons.shp"

IrrigatedLandShapeFileName <- "mfe-irrigated-land-area-2017-SHP/irrigated-land-area-2017-Manawatu.shp"

PAWShapeFileName <- "niFSL_fixedgeom/FSL_Horizons.shp"

ClimateShapeFileName <- "ClimateRegions/ClimateRegions-Horizon.shp"

CASMModelDomainFileName <- "CASMModelDomains/CASMModelDomains.shp"

MPILeachRateLUTFile <- "MPI_Baseline_N_losses_v7.csv"

MPIClassNameLUTFile <- "MPI_LookupNamesNLosses_v5.csv"

LanduseToLanduseLUTFile <- "LanduseToLanduseLookUpTable.csv"

PredictorRasterFileName <- "PredictorRaster 250x250.tif"

LeachRateRasterFileName <- "LeachRateRaster 250x250.tif"

ZoneLanduseLUCRasterFileName <- "ZoneLanduseLUCRaster 250 x 250.tif"

ZoneLanduseLUCCode_To_ClassLUTFileName <- "ZoneLanduseLUCCode_To_ClassLUT.csv"

TargetZonesFileName <- "Target_subzones"

LeachRateLimitsFileName              <- "Table14_2.csv"

source(file.path(ProjectDirectory,"R/CASM-PrePostProcessor/CASM_PrePostProcessorFunctions.R"))
```

Find the total area of each Climate-PAW class within all the target Dairy-LUC combinations, and all the Irrigted Sheep and Beef-LUC combinations.
By Special request from Horizons.
****Don't run this unless you specifically need it!!****
```{r}


# ClimateData=file.path(GISDataDirectory,ClimateShapeFileName)
#                                    LanduseData=file.path(GISDataDirectory,SubZoneLanduseLUCShapeFileName)
#                                    IrrigatedLandData=file.path(GISDataDirectory,IrrigatedLandShapeFileName)
# 
#                                    PAWData=file.path(GISDataDirectory,PAWShapeFileName)
#                                    
#                                    #Load climate spatial data
#                                      ClimateSpatial <- readOGR(ClimateData, stringsAsFactors = FALSE)
#                                      #Make sure the class id is numeric
#                                      ClimateSpatial@data$id <- as.numeric(ClimateSpatial@data$id)
# ClimateSpatial <- spTransform(ClimateSpatial,CRS("+init=epsg:2193") )
#                                      
#                                      #Load the spatial data with the landuse, land use capability and submanagement zones alltogether
#                                      SubZoneLanduseLUCSpatial <- readOGR(LanduseData,stringsAsFactors = FALSE)
#                                      SubZoneLanduseLUCSpatial <- spTransform(SubZoneLanduseLUCSpatial,CRS("+init=epsg:2193") )
#                                      
#                                      #Load irrigated land spatial data
#                                      IrrigatedLandSpatial <- readOGR(IrrigatedLandData,stringsAsFactors = FALSE)
#                                      IrrigatedLandSpatial@data$Irrigated <- as.numeric(IrrigatedLandSpatial@data$Irrigated)
#                                      IrrigatedLandSpatial <- spTransform(IrrigatedLandSpatial,CRS("+init=epsg:2193") )
# 
#                                      
#                                      #Load Plant Available Water (PAW) spatial data
#                                      PAWSpatial <- readOGR(PAWData, stringsAsFactors = FALSE)
#                                      #Convert PAW values to numbers (I don't know why they are characters)
#                                      PAWSpatial$PAW_Cat2 <- as.numeric(PAWSpatial$PAW_Cat2)
# PAWSpatial <- spTransform(PAWSpatial,CRS("+init=epsg:2193") )
# 
# 
# TargetZones <- readOGR(file.path(GISDataDirectory,TargetZonesFileName),TargetZonesFileName, stringsAsFactors = FALSE)
# TargetZones <- spTransform(TargetZones,CRS("+init=epsg:2193") )
# 
# #Select the target zones from the Land use data
# TargetZoneLanduseLUC <- SubZoneLanduseLUCSpatial[which(SubZoneLanduseLUCSpatial$Zone_Code %in% TargetZones$Zone_Code),]
# 
# #only interested in Dairy
# TargetZoneLanduseLUC_Dairy<- TargetZoneLanduseLUC[which(TargetZoneLanduseLUC$RegiScLand =="Dairy"),]
# 
# #only interested in irrigated sheep and beef, so select the sheep and beef
# TargetZoneLanduseLUC_SheepAndBeef <- TargetZoneLanduseLUC[which(TargetZoneLanduseLUC$RegiScLand == "Sheep and/or Beef"),]
# #Intersect with irrigated
# TargetZoneLanduseLUC_SheepAndBeef_Irrigated <- intersect(TargetZoneLanduseLUC_SheepAndBeef,IrrigatedLandSpatial)
# #Select just the Irrigated
# TargetZoneLanduseLUC_SheepAndBeef_Irrigated <- TargetZoneLanduseLUC_SheepAndBeef_Irrigated[which(TargetZoneLanduseLUC_SheepAndBeef_Irrigated$Irrigated == 1),]
# 
# #Interesect the target zones with Climate
# TargetZoneLanduseLUC_Dairy_Climate <- intersect(TargetZoneLanduseLUC_Dairy,ClimateSpatial)
# 
# #And then intersect with PAW
# TargetZoneLanduseLUC_Dairy_Climate_PAW <- intersect(TargetZoneLanduseLUC_Dairy_Climate,PAWSpatial)
# #and add areas
# TargetZoneLanduseLUC_Dairy_Climate_PAW$area <- area(TargetZoneLanduseLUC_Dairy_Climate_PAW)
# #just get the columns we want
# TargetZoneLanduseLUC_Dairy_Climate_PAW <- TargetZoneLanduseLUC_Dairy_Climate_PAW[,c("LUC_CLASS","Zone_Code","Class","id","PAW_Cat2","area")]
# 
# #Now sum the areas for the unique combinations of everything.
# #This solution is from https://stackoverflow.com/questions/27137174/sum-a-rows-within-a-column-for-each-unique-combination-r
# library(data.table)
# #Do the summing
# TargetZoneLanduseLUC_Dairy_Climate_PAW_summedAreas <- setDT(TargetZoneLanduseLUC_Dairy_Climate_PAW@data)[, Sum := round(sum(area)/10000,1), by = .(LUC_CLASS,Zone_Code,Class,PAW_Cat2)][]
# 
# #Get the unique values
# TargetZoneLanduseLUC_Dairy_Climate_PAW_summedAreas <- unique(TargetZoneLanduseLUC_Dairy_Climate_PAW_summedAreas[,-6])
# 
# #Rename
# names(TargetZoneLanduseLUC_Dairy_Climate_PAW_summedAreas) <- c("LUC","Zone","Climate","Climate No.","PAW","Area (Ha)")
# 
# #Add the landuse
# DairyData$Landuse <- "Dairy"
# 
# 
# #Repeat for Irrigated Sheep and Beef
# TargetZoneLanduseLUC_SheepAndBeef_Irrigated_Climate<- intersect(TargetZoneLanduseLUC_SheepAndBeef_Irrigated,ClimateSpatial)
# TargetZoneLanduseLUC_SheepAndBeef_Irrigated_Climate_PAW <- intersect(TargetZoneLanduseLUC_SheepAndBeef_Irrigated_Climate,PAWSpatial)
# TargetZoneLanduseLUC_SheepAndBeef_Irrigated_Climate_PAW$area <- area(TargetZoneLanduseLUC_SheepAndBeef_Irrigated_Climate_PAW)
# TargetZoneLanduseLUC_SheepAndBeef_Irrigated_Climate_PAW <- TargetZoneLanduseLUC_SheepAndBeef_Irrigated_Climate_PAW[,c("LUC_CLASS","Zone_Code","Class","id","PAW_Cat2","area")]
# 
# 
# TargetZoneLanduseLUC_SheepAndBeef_Irrigated_Climate_PAW_summedAreas <- setDT(TargetZoneLanduseLUC_SheepAndBeef_Irrigated_Climate_PAW@data)[, Sum := round(sum(area)/10000,1), by = .(LUC_CLASS,Zone_Code,Class,PAW_Cat2)][]
# 
# TargetZoneLanduseLUC_SheepAndBeef_Irrigated_Climate_PAW_summedAreas <- unique(TargetZoneLanduseLUC_SheepAndBeef_Irrigated_Climate_PAW_summedAreas[,-6])
# 
# names(TargetZoneLanduseLUC_SheepAndBeef_Irrigated_Climate_PAW_summedAreas) <- c("LUC","Zone","Climate","Climate No.","PAW","Area (Ha)")
# 
# 
# #Add the landuse
# SheepAndBeefIrrigatedData$Landuse <- "SheepAndBeef_Irrigated"
# 
# #Combine the Dairy and the SheepAndBeef data
# CombinedData <- rbind(DairyData,SheepAndBeefIrrigatedData)
# #Reorder the columns
# CombinedData <- CombinedData[,c("Zone","Landuse","LUC","Climate","PAW","Area (Ha)")]
# 
# #Re-order the rows
# CombinedData <- CombinedData[order(CombinedData$Zone, CombinedData$Landuse, CombinedData$LUC, CombinedData$Climate, CombinedData$PAW),]
# 
# #Write to a file
# write.table(CombinedData, file.path(DataDirectory,"TargetZone_Dairy_and_Irrigated_Sheep_And_Beef_Categorised_Areas.csv"),sep=",",row.names=FALSE,quote=FALSE)
```


load data
```{r}
#REC data has been sourced from the NIWA website. It has cut down versions of the attribute names, e.g. nzsegment is nzsgmnt. Keep an eye on this when comparing to other data sources that may have the full RECV2 attribute names.
RECReachNetwork <- readOGR(dsn =file.path(GISDataDirectory,REC_rivers),
                           layer = "RECV2-Riverlines-Horizons")
RECReachNetwork <- spTransform(RECReachNetwork,CRS("+init=epsg:2193") )

#RECWatersheds <- readOGR(dsn = file.path(GISDataDirectory,REC_Catchments),
#                         layer = "RECV2-Watersheds-Horizons")
#RECWatersheds <- spTransform(RECWatersheds,CRS("+init=epsg:2193") )

#Load the mean flow data for the REC V2. This is provided in an rdata file which contains the data frame REC2MeanFlow, with three columns, "nzsegment","QMean", and "us_catarea"
load(file.path(DataDirectory, REC_MeanFlowFile))

#Load the CASM Model Domains spatial file
CASMModelDomains <- readOGR(file.path(GISDataDirectory,CASMModelDomainFileName), stringsAsFactors = FALSE)
#Explicitly set projection to NZTM
CASMModelDomains <- spTransform(CASMModelDomains,CRS("+init=epsg:2193") )

#Load the Horizon total nitorigen load measurement sites, previously prepared by Caroline Fraser and called "HZLoads
load(file.path(DataDirectory,"N_ExpCoeff_Est_HZ_Feb20.rdata"))
#Select just the TN sites
MeasurementSites <- HZLoads[which(HZLoads$npID=="TN"),]

#Calculate loads as t/y
MeasurementSites$load <- round(MeasurementSites$ExpCoef * MeasurementSites$CATCHAREA / 10000,2)
MeasurementSites$load_Uci <- round(MeasurementSites$ExpCoef_Uci_ * MeasurementSites$CATCHAREA / 10000,2)
MeasurementSites$load_Lci <- round(MeasurementSites$ExpCoef_Lci_ * MeasurementSites$CATCHAREA / 10000,2)

#Create a spatial points object set to NZTM
MeasurementSitesSpatial <-SpatialPointsDataFrame(coords = MeasurementSites[,c("NZTM.X","NZTM.Y")],
                                               data = MeasurementSites[,1:13],
                                               proj4string = CRS("+init=epsg:2193"))
#Find which model domain they are in
MeasurementSitesSpatial@data$CASMDomain <- (MeasurementSitesSpatial %over% CASMModelDomains)$CASMModel

#Save a copy for external use
writeOGR(MeasurementSitesSpatial,dsn = file.path(GISDataDirectory,"MeasurementSites"),"MeasurementSites",driver='ESRI Shapefile',overwrite_layer = TRUE)

#Load the leach rate maximums set out by Horizons in their plan, and ammended in their proposed plan change 2. This includes a 4 stepped change for year's 1, 5,10 and 20
LeachRateLimits <- read.table(file.path(DataDirectory,LeachRateLimitsFileName), sep=",", header=TRUE)


#Load the point sources of nitrogen, previously prepared by Caroline Fraser. Unfortunately they don't have nzsgmnt data. note that an error was found for the NZTM.X position of the Fonterra at Pahiatua site. Originally it was 1859554.9 but it should be 1839554.9. This has been corrected on the LWP sharepoint version of the 20200201_HorizonsRiverCriteria.xlsx file, and the Tim Kerr version of the PointSourcesSummaryPC2_YE2012_04.csv file.
PointSourceSites <- read.csv(file.path(DataDirectory,"PointSourcesSummaryPC2_YE2012_04.csv"))

#Create a spatial points object set to NZTM
PointSourceSitesSpatial <-SpatialPointsDataFrame(coords = PointSourceSites[,c("NZTM.X","NZTM.Y")],
                                               data = PointSourceSites[,1:5],
                                               proj4string = CRS("+init=epsg:2193"))
#Find which catchment each point is in
PointSourceSitesSpatial@data$CASMDomain <- (PointSourceSitesSpatial %over% CASMModelDomains)$CASMModel

#Save a copy for external use
writeOGR(PointSourceSitesSpatial,dsn = file.path(GISDataDirectory,"PointSourceSites"),"PointSourceSites",driver='ESRI Shapefile',overwrite_layer = TRUE)

#Load the subzone polygons
SubZonePolygons <- readOGR(dsn =file.path(GISDataDirectory,SubZones),
                           layer = SubZones)
SubZonePolygons <- spTransform(SubZonePolygons,CRS("+init=epsg:2193") )

# #For mapping purposes it is useful to know which CASM model each zone is within. This is (mostly) done by the following few lines. However, for zones bordering two models, it sometimes selectes the wrong model domain, so this file has been externally manually edited. Be sure that you want to overwrite it!
# #Add an attribute showing which model domain a zone is within
# SubZonePolygons@data$CASMDomain <- (SubZonePolygons %over% CASMModelDomains)$CASMModel
# 
# #Save a copy for external use
# writeOGR(SubZonePolygons,dsn = file.path(GISDataDirectory,"WaterManagementZonesForMapping"),"WaterManagementZonesForMapping",driver='ESRI Shapefile',overwrite_layer = FALSE)

#Load the network outlet reach names lookup table. This has been manually prepared, and may need editing if the network changes to include outlet reaches not yet included in this file
OutletReachNames <- read.csv(file.path(DataDirectory,OutletReachNamesFile), stringsAsFactors = FALSE)

#Load the spatial data with the landuse, land use capability and submanagement zones alltogether
#LanduseLUCSpatial <- readOGR(dsn =file.path(GISDataDirectory,LanduseLUCShapefileName),
#                           layer = LanduseLUCShapefileName)
#LanduseLUCSpatial <- spTransform(LanduseLUCSpatial,CRS("+init=epsg:2193") )
SubZoneLanduseLUCSpatial <- readOGR(file.path(GISDataDirectory,SubZoneLanduseLUCShapeFileName))
SubZoneLanduseLUCSpatial <- spTransform(SubZoneLanduseLUCSpatial,CRS("+init=epsg:2193") )



#Load the leachingrate data if it exists
LeachRate <- raster(file.path(GISDataDirectory,LeachRateRasterFileName))

#**********************************************************
#If the leach rate raster file is missing or needs to be re-created then use the following:
#Takes 5 minutes at 250 m
#Note addition of timing to see how long it takes
# tic()
# LeachRate <- LeachRateRasterCreator()
# toc()
# #And save it for nexttime
# writeRaster(LeachRate,file.path(GISDataDirectory,LeachRateRasterFileName),overwrite=TRUE)
#******************************************************************

#Load the ZoneLanduseLUC raster if it exists
ZoneLanduseLUCRaster <- raster(file.path(GISDataDirectory,ZoneLanduseLUCRasterFileName))
#**********************************************************
##If the ZoneLanduseLUCRaster raster file is missing or needs to be re-created then use the following:
##Takes 5 minutes at 250 m
##Note addition of timing to see how long it takes
#tic()
#ZoneLanduseLUCRaster <- ZoneLanduseLUCRasterCreator(ZoneLanduseLUCPolygons = ZoneLanduseLUCPolygons,LeachRates = LeachRate)
#toc()
#And save it for nexttime
#writeRaster(LeachRate,file.path(GISDataDirectory,LeachRateRasterFileName),overwrite=TRUE)
#******************************************************************
```
I need to analyse each management sub zone to determine how much area (in hectares) each landuse-LUC combination takes up.
Unfortunately there is a decrepancy between provided data for the sub management zones. Upon query to Horizons (See email exchange between Ton Snelder and Stephen Collins- Horizons on 17th Feb 2020), the zones within the "Water_Management_Subzones" ESRI shapefile trumps those within the "Landuse_LUC Original". So the land use and LUC is extracted from one file, then intersected with the other.This proved to be problematic because both files had topology errors, primarily small circles in the boundaries, so the files had to be "cleaned". This proved to be most effectively done in QGIS. They were then intersected in QGIS, and then aggregated by RegiScLand, LUC_CLASS and Zone_Code in R (see below) before being saved as a file so that the painfull process doesn't have to be repeated.
```{r}

#Intersect the Landuse and LUC with the sub-management zones
#SubZoneLanduseLUCSpatial <- intersect(LanduseLUCSpatial,SubZonePolygons)

#Aggregate on sub_zone, Landuse and LUC and save for later
#SubZoneLanduseLUCSpatial <- aggregate(SubZoneLanduseLUCSpatial,by=c("RegiScLand","LUC_CLASS","Zone_Code"))
#writeOGR(bob,GISDataDirectory,ZoneLanduseLUC,driver='ESRI Shapefile')

#Find the area of each Landuse-LUC combination for each sub-zone
SubZoneLanduseLUCSpatial$hectares <- round(raster::area(SubZoneLanduseLUCSpatial) / 10000,1)

#Create a new combined name
SubZoneLanduseLUCSpatial$CombinedClassName <- with(SubZoneLanduseLUCSpatial@data, paste0(Zone_Code,"-",RegiScLand,"-",LUC_CLASS))

#Now break this into each individual polygon. I need to do this before getting the leach rates so that I don't average the leach rates without accounting for area. This is an alternative to using weights when doing the extract.

# #Start with a test for a single area
# Whau_3b <- SubZoneLanduseLUCSpatial[SubZoneLanduseLUCSpatial$Zone_Code == "Whau_3b",]
# Whau_3b_Sf <-as(Whau_3b, "sf")
# Whau_3b_Sf_single = st_cast(Whau_3b_Sf,"POLYGON")
# 
# Whau_3b_leach <- raster::extract(LeachRate, Whau_3b, fun = mean, na.rm=TRUE, sp=TRUE)
# Whau_3b_leach_weighted <- raster::extract(LeachRate, Whau_3b, fun = mean, na.rm=TRUE, sp=TRUE,weights = TRUE)
# 
# Whau_3b_Sf_single_leach <- raster::extract(LeachRate, Whau_3b_Sf_single, fun = mean, na.rm=TRUE, sp=TRUE)
# Whau_3b_Sf_single_leach$hectares <- raster::area(Whau_3b_Sf_single_leach) / 10000
# 
# Whau_3b_Sf_single_leach_weighted <- raster::extract(LeachRate, Whau_3b_Sf_single, fun = mean, na.rm=TRUE, sp=TRUE, weights = TRUE)
# Whau_3b_Sf_single_leach_weighted$hectares <- raster::area(Whau_3b_Sf_single_leach_weighted) / 10000

#I found that the sum of the loads (leach rate x area) after weighted extraction is very close to the value determined from the raster. When I repeat using singlepart polygons, the number is simmilar.
#The conclusion is the weighting is required, and that it works without having to convert to single parts.

##Get the average leach rate for each polygon THIS TAKES ABOUT 10 MINUTES for 250 x 250 m
tic()
leachvalues <- raster::extract(LeachRate, SubZoneLanduseLUCSpatial, fun = mean, na.rm=TRUE, sp=TRUE, weights=TRUE)
toc()
```


Get the "nzsgmnt" attributes of the lowest reach in each of the management subzones
```{r}
SubZoneOfEachReach <- RECReachNetwork %over% SubZonePolygons #Note this takes about a minute to do
RECReachNetwork$SubZoneCode <- SubZoneOfEachReach$Zone_Code

#Work through each management zone to find the reach with the greatest distance to the headwater (the hdw_dst attribute). . I tried doing this based on the least largest area (the CUM_ARE attribute) but there were some zero values, I also tried distance to the sea (the LENGTHD attribute, but near the coast I was getting small reaches that were not the main river channel, but were closer to the sea)
ManagementSubZoneOutletReaches <- lapply(seq_along(SubZonePolygons$Zone_Code), function(SingleSubZoneIndex){
  #browser()
  CurrentSubZone <- SubZonePolygons$Zone_Code[SingleSubZoneIndex]
  CurrentSubZoneReaches <- RECReachNetwork[RECReachNetwork$SubZoneCode == CurrentSubZone,]
  OutletReach <- CurrentSubZoneReaches$nzsgmnt[which.max(CurrentSubZoneReaches$hdw_dst)]
  return(data.frame(SubZone = CurrentSubZone,nzsgmnt = OutletReach))
})
#Convert the list into a dataframe
ManagementSubZoneOutletReachesDF <- do.call(rbind,ManagementSubZoneOutletReaches)
```


From the load sites, point source sites, and water management subzones outlets, create the required network
```{r}
AllPoints <- c(MeasurementSites$nzsegment, PointSourceSites$nzsegment, ManagementSubZoneOutletReachesDF$nzsgmnt)
LoadNetwork <- lapply(AllPoints, function(x) {DownstreamReachFinder(RECNetwork = RECReachNetwork, SourceReach = x)} )
CompleteNetwork <- unlist(LoadNetwork)
CompleteNetwork <- CompleteNetwork[!duplicated(CompleteNetwork)]

CompleteSpatialNetwork <- RECReachNetwork[RECReachNetwork$nzsgmnt %in% CompleteNetwork,]

CompleteSpatialNetwork@data$CASMDomain <- (CompleteSpatialNetwork %over% CASMModelDomains)$CASMModel
```

Then create a tributary table ready for CASM
```{r}

NetworkLabelList <- NetworkLabeler(CompleteSpatialNetwork)


#Add the tributary labels to the network
SegmentToLabelLookUpTable <- do.call(rbind,NetworkLabelList)
CompleteSpatialNetwork@data$Label <- SegmentToLabelLookUpTable$Label[match(CompleteSpatialNetwork@data$nzsgmnt,SegmentToLabelLookUpTable$nzsgmnt)]
#Add the prefixed labels to the network
SegmentToPrefixedLabelLookUpTable <- ReachLabeler(NetworkLabelList, OutletReachNames)
CompleteSpatialNetwork@data$PrefixedLabel <- SegmentToPrefixedLabelLookUpTable$Prefixedlabel[match(CompleteSpatialNetwork@data$nzsgmnt,SegmentToPrefixedLabelLookUpTable$nzsgmnt)]

#Add the 
#Save the network as a spatial file
writeOGR(CompleteSpatialNetwork, file.path(GISDataDirectory), "CASM-StreamNetwork", driver="ESRI Shapefile",overwrite_layer=TRUE)

TributaryConnectionTable <- TributaryConnectionCreator(RECNetwork = CompleteSpatialNetwork, TributaryLabelList = NetworkLabelList)
```

Then create a point source table ready for CASM,
a measurement site table ready for CASM,
and a diffuse inputs table ready for CASM
```{r}
#Create a dataframe of just the nzsegment number and the site name
PointSourceNodes <- PointSourceSites[,c("Site.Name","nzsegment")]

#Standardise the column names so that it matches the expected format in the CASMNodeTablePreparer() function
names(PointSourceNodes) <- c("NodeName","nzsgmnt")

#Prepare the CASM table with the bonus nzsgmnt column
PointSourceTable <- CASMNodeTablePreparer(CASMRECNetwork = CompleteSpatialNetwork, NetworkLabelList = NetworkLabelList, TributaryConnectionTable = TributaryConnectionTable,CASMNodes = PointSourceNodes )

#rename the columns to match the CASM requirements
names(PointSourceTable) <- c("nzsgmnt","Point Source Name","Receiving Stream","Location (km)")
 
#Need to add the point source load to the table
PointSourceTable$"Annual Load (kg/yr)" <- round(PointSourceSites$TN.kgpy[match(PointSourceTable$nzsgmnt,PointSourceSites$nzsegment)],0)
```



#Repeat for the measurement sites
```{r}
MeasurementSiteNodes <- MeasurementSites[,c("sID","nzsegment")]
names(MeasurementSiteNodes) <- c("NodeName","nzsgmnt")
MeasurementSiteTable <- CASMNodeTablePreparer(CASMRECNetwork = CompleteSpatialNetwork, NetworkLabelList = NetworkLabelList, TributaryConnectionTable = TributaryConnectionTable,CASMNodes= MeasurementSiteNodes)

#rename the columns to match the CASM conventions
names(MeasurementSiteTable) <- c("nzsgmnt","Site Name or No","Target Stream","Downstream Location (km)")

#Add the mean annual flow to the table
MeasurementSiteTable$"Mean flow (m3/s)" <- round(REC2MeanFlow$QMean[match(MeasurementSiteTable$nzsgmnt, REC2MeanFlow$nzsegment)],1)

#Add a variety of other fields from the Measurement Site data
MeasurementSiteTable$'Load (kg/yr)' <- round(MeasurementSites$load[match(MeasurementSiteTable$"Site Name or No", MeasurementSites$sID)],1)
MeasurementSiteTable$'Load Lci (kg/yr)' <- round(MeasurementSites$load_Lci[match(MeasurementSiteTable$"Site Name or No", MeasurementSites$sID)],1)
MeasurementSiteTable$'Load Uci (kg/yr)' <- round(MeasurementSites$load_Uci[match(MeasurementSiteTable$"Site Name or No", MeasurementSites$sID)],1)
```

#Repeat for diffuse inputs. This is a special case, because once the points have been found, they need to be joined with all the different landuse/LUC options
```{r}
#Start with all the diffuse source input nodes. These are the sub-management zone outlets
DiffuseInputsSiteNodes <- ManagementSubZoneOutletReachesDF
names(DiffuseInputsSiteNodes) <- c("NodeName","nzsgmnt")

#Build up the table of tributary names and locations associated with the diffuse source input sites
DiffuseInputsSiteTable <- CASMNodeTablePreparer(CASMRECNetwork = CompleteSpatialNetwork, NetworkLabelList = NetworkLabelList, TributaryConnectionTable = TributaryConnectionTable,CASMNodes= DiffuseInputsSiteNodes)

#Now create a bigger version, with a row for each of the different landuse/LUC combinations within each sub-management zone
DiffuseInputsSiteExtendedTable <- SubZoneLanduseLUCSpatial@data

#Add the locations that we have just previously determined
DiffuseInputsSiteExtendedTable[,c("TribLocn","TribName")] <- DiffuseInputsSiteTable[match(SubZoneLanduseLUCSpatial@data$Zone_Code, DiffuseInputsSiteTable$CASMNodeName),c("TribLocn","TribName")]

#Add the leach rates
DiffuseLeachRateData <- DiffuseLoadTableCreator(ZoneLanduseLUCRaster = ,LeachRates = LeachRate)
DiffuseInputsSiteExtendedTable$"LeachRates"<- DiffuseLeachRateData$LeachRate[match(DiffuseInputsSiteExtendedTable$CombinedClassName,DiffuseLeachRateData$CombinedClassName)]

#Need to use raster-calculated area rather than polygon areas
DiffuseInputsSiteExtendedTable$`RasterBased Land Area (ha)` <- DiffuseLeachRateData$Hectares[match(DiffuseInputsSiteExtendedTable$CombinedClassName,DiffuseLeachRateData$CombinedClassName)]
#Remove all the surplus combined names. The raster version has much less.
DiffuseInputsSiteExtendedTable <- DiffuseInputsSiteExtendedTable[complete.cases(DiffuseInputsSiteExtendedTable),]

#I now need to adjust the locations of all the different landuse/LUC options for a single diffuse source point so that they are not all on exactly the same spot.
#Work along each sub management zone, get all the landuse/LUC classes, and increment the locations by 0.1 km
DiffuseInputsSiteExtendedTable$AdjustedTriblocn <- DiffuseInputsSiteExtendedTable$TribLocn
UniqueSubZones <- unique(DiffuseInputsSiteExtendedTable$Zone_Code)
for(SubZoneIndex in seq_along(UniqueSubZones)) {
  #get the subzone of interest
  SubZone <- UniqueSubZones[SubZoneIndex]
  
  #Get all the landuse/LUC classes in the subzone
  RowsOfInterest <- which(DiffuseInputsSiteExtendedTable$Zone_Code == SubZone)
  DiffuseInputsSiteExtendedTable$AdjustedTriblocn[RowsOfInterest] <- DiffuseInputsSiteExtendedTable$TribLocn[RowsOfInterest] + seq(0,by = 0.01, length.out = length(RowsOfInterest))
}

#rename the columns to match the CASM conventions
names(DiffuseInputsSiteExtendedTable) <- c("Landuse","LUC","Zone_Code","Polygon Land Area (ha)","Node Name","Original location (km)", "Receiving Stream","Export Coeff (kg/ha/yr)","Land Area (ha)","Discharge Location (km)")

```


Create a plot
```{r}
# plot(SubZonePolygons, col = "transparent")
# plot(CompleteSpatialNetwork, col = "blue", add=TRUE)
# plot(PointSourceSitesSpatial, add=TRUE, col = "red")
#plot(MeasurementSitesSpatial, add=TRUE, col = "black")
```
Or another plot
```{r}
# #Put all the spatial data in a list for simplicity
# SpatialData <- list(MeasurementSites=MeasurementSitesSpatial, PointSourceSites=PointSourceSitesSpatial,
#                     SubZones=SubZonePolygons,RiverNetwork=CompleteSpatialNetwork)
# #Get the extents of the area in lat lon
# MapExtentLatLon <- extent(projectExtent(SubZonePolygons, crs('+init=epsg:4326')))
# #Expand the extents to provide extents for the topographical map to download
# MapExtents <- MapExtentLatLon + 0.005
# LINZAPIToken <- "85df745fa5d446fea241dd5ae40add85"
# #And use those extents to get the Topo250 data. Note that I seem to need to download the data first, then load it into R.
# download.file(paste0("https://data.linz.govt.nz/services;key=",LINZAPIToken,"/wms?service=WMS&version=1.1.1&request=GetMap&layers=layer-50798&format=image/geotiff&width=1456&height=1600&bbox=",MapExtents@xmin,",",MapExtents@ymin,",",MapExtents@xmax,",",MapExtents@ymax),destfile <- file.path(GISDataDirectory,"TopoNZ.tif"))
# Topo250Map <- stack(file.path(GISDataDirectory,"TopoNZ.tif"))
# #Need to set NA values to 0
# values(Topo250Map)[is.na(values(Topo250Map))] <- 0
# 
# #Reproject the other spatial data to the maps projection ready for plotting
# reprojected.data <- lapply(SpatialData, spTransform,Topo250Map@crs)
# list2env(reprojected.data,env=.GlobalEnv)
# 
# {
# plotRGB(Topo250Map,colNA="white")
# plot(SubZones, add=TRUE)
# points(MeasurementSites,pch=20)
# points(PointSourceSites, pch = 8, col = "dark green")
# lines(RiverNetwork, col = "blue")
# legend("topleft",bty="n",legend=c("SubZones","Measurement \nSites","Point Source Sites","River \nNetwork"),pch=c(0,20,8,NA),pt.cex=c(1.3,1,1,NA),merge=TRUE,lty=c(-1,-1,-1,1),col=c("black","black","dark green","blue"))
# north.arrow(xb=par("usr")[1] + 0.0015,yb=par("usr")[3]+0.0009, len = 0.0002)
# map.scale(xc=par("usr")[1] + 0.0015,yc=-42.89077,len=1/(1110.91/2.5), units= "metres", ndivs=1, subdiv = 250)
# }
# 
# #Generate a plot file
# dev.copy(png,file=file.path(DataDirectory,
#                             "OverviewMap.png")
#          ,width=19,height=28,units="cm",res=600,family="Arial",pointsize=8)
#invisible(dev.off())
```
Or another plot
```{r}
#Reproject the other spatial data to the maps projection ready for plotting
SpatialData <- list(MeasurementSites=MeasurementSitesSpatial, PointSourceSites=PointSourceSitesSpatial,
                    SubZones=SubZonePolygons,RiverNetwork=CompleteSpatialNetwork)
reprojected.data.WGS84 <- lapply(SpatialData, spTransform,CRS("+init=epsg:4326"))


map <- leaflet::leaflet() %>% 
  leaflet::addProviderTiles(providers$OpenStreetMap) %>%
  setView(lng=175.5,lat=-40.0,zoom=8) %>% 
  addPolygons(data = reprojected.data.WGS84$SubZones, color = "black", weight = 3, fillColor = "transparent", label = ~htmlEscape(Zone_Code)) %>%
  addCircleMarkers(data = reprojected.data.WGS84$MeasurementSites, color = "red",label = ~htmlEscape(sID)) %>%
  addCircleMarkers(data = reprojected.data.WGS84$PointSourceSites, color = "black", label = ~htmlEscape(Site.Name)) %>%
  addPolylines(data = reprojected.data.WGS84$RiverNetwork, color= "blue", label = ~htmlEscape(PrefixedLabel))
map

#save the mapdata as an R file so that it can be used in an RShinyApp
saveRDS(reprojected.data.WGS84,file.path(ProjectDirectory,"ShinyApp/Data","SpatialData.RDS"))
```


The tributary connection table needs to be converted to an Excel Spreadsheet.


I need to create an excel table of CASM-Nodes, CASM-Reach-Names, CASM-Reach-Locations, CASM-Reach-Areas, CASM-Reach-Exp.Coeff
```{r}


Out <- createWorkbook()

addWorksheet(Out, "River Network")

writeData(Out, sheet = "River Network", x = TributaryConnectionTable[c("Tributary Name","Confluence Stream","Confluence Location (km)")])

addWorksheet(Out, "Point Source")

writeData(Out, sheet = "Point Source", x = PointSourceTable[,-1])

addWorksheet(Out, "Water Quality Stations")

writeData(Out, sheet = "Water Quality Stations", x = MeasurementSiteTable[,-1])

addWorksheet(Out, "Diffuse Inputs")


writeData(Out, sheet = "Diffuse Inputs", x = DiffuseInputsSiteExtendedTable[,c("Node Name","Receiving Stream","Discharge Location (km)","Land Area (ha)","Export Coeff (kg/ha/yr)")])

saveWorkbook(Out, file.path(DataDirectory,"CASM-Inputs.xlsx"), overwrite = T)
```
 By way of a check, it will be helpful to compare the total sub-management zone loads from the gridded leachrate data with the total sub-management zone loads from the zone/landuse/LUC data.
 Start with the leach rate raster data, and get the average leachrate for each zone and multiply by the area.
 Note that  I need to use the subzones from the SubZone
 
 Then, as a check, get the load for each zone-landuse-LUC combination, and sum in each zone.
 It would also be good to add a check of total load in catchments upstream of a water quality network being more than the total load measured. If they were less, then the attenuation would have to be greater than 1!
```{r}
#Note that to ensure I am comparing apples with apples, I am using the SubZoneLandUseLUCSpatial data to find the SubZone areas (rather than using the pre-prepared cleaned sub zone spatial data which has been "cleaned" so is slightly different in area!!)
test <- unionSpatialPolygons(SubZoneLanduseLUCSpatial,IDs = SubZoneLanduseLUCSpatial@data$Zone_Code )
testid <- sapply(slot(test, "polygons"), function(x) slot(x, "ID"))
test2 <- SpatialPolygonsDataFrame(test,data.frame(Zone_Code = testid,row.names = testid))

Zoneleachrates <- raster::extract(LeachRate, test2, fun = mean, na.rm=TRUE, sp=TRUE, weights = TRUE)
Zoneleachrates$area <- raster::area(Zoneleachrates)
Zoneleachrates$loads <- with(Zoneleachrates@data,layer * area / 10000)

DiffuseInputsSiteExtendedTable$load <- DiffuseInputsSiteExtendedTable$`Export Coeff (kg/ha/yr)` * DiffuseInputsSiteExtendedTable$`Land Area (ha)`
library(plyr)
bob <- ddply(DiffuseInputsSiteExtendedTable, "Zone_Code", function(x) sum(x$load, na.rm=TRUE))

ddply(DiffuseInputsSiteExtendedTable, "Zone_Code", function(x) sum(x$'Land Area (ha)', na.rm=TRUE))

#Ideally the loads from the raster and the DiffuseinputsSiteExtendedTable would be the same, but they are not!!
#But they are close for most water management sub-zones
charlie <- cbind(Zoneleachrates@data,bob)
charlie$load_diff <- charlie$loads - charlie$V1
charlie$load_diff_percent <- round(charlie$load_diff / charlie$loads * 100,0)
print(charlie)
```
 


