---
title: "R Notebook to preprocess water quality data for use with CASM"
output: html_notebook
---

Load libraries
```{r}
if (!require(rgdal)) install.packages("rgdal"); library(rgdal)                #used for spatial processing
if (!require(gdalUtils)) install.packages("gdalUtils"); library(gdalUtils)    #used for spatial processing
if (!require(sp)) install.packages("sp"); library(sp)                         #used for spatial processing
if (!require(GISTools)) install.packages('GISTools'); library(GISTools)
if (!require(dplyr)) install.packages('dplyr'); library(dplyr)
if (!require(sf)) install.packages('sf'); library(sf)
if (!require(raster)) install.packages('raster'); library(raster)
if (!require(cleangeo)) install.packages('cleangeo'); library(cleangeo)

#if (!require(readxl)) install.packages('readxl'); library(readxl)
if (!require(openxlsx)) install.packages('openxlsx'); library(openxlsx)
#if (!require(xlsx)) install.packages('xlsx'); library(xlsx)

if (!require(leaflet)) install.packages('leaflet'); library(leaflet) #Package with mapping functions
if (!require(viridis)) install.packages('viridis'); library(viridis)   #Provides color palettes that are good for mapping rain and account for colour blindness
if (!require(shiny)) install.packages('shiny'); library(shiny)
if (!require(mapview)) install.packages('mapview'); library(mapview)
if (!require(htmltools)) install.packages('htmltools'); library(htmltools)
```

Some functions
```{r}

#' A function to find the REC network downstream of a reach
#'
#'This function generates a vector of the reach ID numbers (nzsegment attribute) downstream of a reach. It uses the REC V2.4 network. See \href{https://niwa.co.nz/freshwater-and-estuaries/management-tools/river-environment-classification-0}{NIWA REC V2} for details about REC V2.
#'@param RECNetwork An REC V2 network (either dataframe of spatial dataframe), with at least nzsgmnt, TO_NODE and FROM_NO attributes
#'@param SourceReach The reach number (i.e. nzsgmnt attribute) of the reach for which the downstream network is required
#'@author Tim Kerr, \email{Tim.Kerr@@Rainfall.NZ}
#'@return A vector of reach numbers (nzsgmnt attributes)
#'@keywords REC River Environment Classification
#'@export
DownstreamReachFinder <- function(RECNetwork=RECReachNetwork,SourceReach=7239110){ #The reach ID is for the Manawatu at Teachers College water quality reporting site

  #Initialise the vector of reach ID's downstream of the source
  DownstreamReaches <- SourceReach
  
  #Identify the row index of the source reach
  SourceSiteReachIndex<-which(RECNetwork$nzsgmnt==SourceReach)
  
  #Identify the reach immediately downstream of the source reach
  downstream_index<-which(RECNetwork$FROM_NO==RECNetwork$TO_NODE[SourceSiteReachIndex])
  
  #downstream_reach<-RECNetwork$nzsgmnt[downstream_index]
  
  #Sequentially work downstream
  while (length(downstream_index)>0) {
     DownstreamReaches <- c(DownstreamReaches,RECNetwork$nzsgmnt[downstream_index])
     downstream_index<-which(RECNetwork$FROM_NO==RECNetwork$TO_NODE[downstream_index])
     #downstream_index<-next_downstream_index
  } #end of while
  return(DownstreamReaches)
}

#' A function to label an REC network based on tributary size
#'
#'This function crawl up an REC network and numbers the tributaries. It starts from the bottom and work up to the first intersection. It decides which branch is the primary and which is a secondary, based on which is the longest to the headwaters, then gives a new number to the smaller tributary and keeps going. It uses the REC V2.4 network. See \href{https://niwa.co.nz/freshwater-and-estuaries/management-tools/river-environment-classification-0}{NIWA REC V2} for details about REC V2.
#'@param RECNetwork An REC V2 network (either dataframe of spatial dataframe), with at least nzsgmnt, TO_NODE, FROM_NO and hdw_dst attributes
#'@author Tim Kerr, \email{Tim.Kerr@@Rainfall.NZ}
#'@return A list (one for each each independent network/diconnected catchment)) of vectors of tributary labels, and a side effect of a file called "OutletReaches.csv" listing the nzsgmnt attributes of the reaches that are considered to be at the bottom of the network.
#'@keywords REC River Environment Classification
#'@export
NetworkLabeler <- function(RECNetwork=MyREC){

  #Find the row indices of all the outlet reach's by finding which "to" nodes  don't have a corresponding "from" node
  OutletReachIndices <- which(!RECNetwork$TO_NODE %in% RECNetwork$FROM_NO)
  names(OutletReachIndices) <- 1:length(OutletReachIndices)
  
  #Save the outlet reaches to an external file so that we can figure out their names manually
  write.table(RECNetwork@data$nzsgmnt[OutletReachIndices],file.path(DataDirectory,"OutletReaches.csv"),sep=",",row.names = FALSE)
  
  #Crawl each network in turn
  ReachLabels <- lapply(OutletReachIndices, function(OutletReachIndex) {   
    #Initialise the label list
    RowNumber          <- 1
    CurrentLabel       <- 1
    Labels             <- data.frame(nzsgmnt=NA,Label=NA)
    Labels[RowNumber,] <- c(RECNetwork$nzsgmnt[OutletReachIndex],1)
    
    CurrentReachIndex  <- OutletReachIndex
    upstream_indices   <- which(RECNetwork$TO_NODE==RECNetwork$FROM_NO[CurrentReachIndex])
    LeftToDoIndices    <- upstream_indices
    
    while (length(LeftToDoIndices) > 0) {
      #Check if there are some upstream indices
      BiggestBranchIndex <- which.max(RECNetwork$hdw_dst[upstream_indices])
      
      CurrentReachIndex  <- upstream_indices[BiggestBranchIndex]
      LeftToDoIndices    <- LeftToDoIndices[LeftToDoIndices != CurrentReachIndex]
      RowNumber          <- RowNumber + 1
      
      Labels[RowNumber,] <- c(RECNetwork$nzsgmnt[CurrentReachIndex],CurrentLabel)
      upstream_indices   <- which(RECNetwork$TO_NODE==RECNetwork$FROM_NO[CurrentReachIndex])
      if (length(upstream_indices) == 0) {
        CurrentLabel = CurrentLabel + 1
        upstream_indices <- LeftToDoIndices[which.max(RECNetwork$hdw_dst[LeftToDoIndices])]
      } else {
        LeftToDoIndices <- c(upstream_indices,LeftToDoIndices)
      }
    }
    return(Labels)
  })


  return(ReachLabels)
}

#' A function to determine where each tributary connects to its parent river. This is needed to provide the river network connectivity table used by CASM.
#' CASM understands a network in terms of Tributary Names, Confluence Names and Confluence Locations.
#' Confluence Name is the name of the river that a tributary flows into.
#' Confluence Location is the distance along the confluence from its start, that the tributary joins it.
#'
#'@param RECNetwork An REC V2 network (either dataframe of spatial dataframe)
#'@param TributaryLabelList A list of tributary labels. One llist for each independent/disconnected catchment. The output of the NetworkLabeler() function
#'@param OutletReachNameLookUpTable A data frame of outlet reach nzsgmnt numbers and real-world names.
#'@author Tim Kerr, \email{Tim.Kerr@@Rainfall.NZ}
#'@return A dataframe. One row for each tributary. Columns of nzsgmnt, tributary name, confluence name, confluence location in kilometres.
#'@keywords REC River Environment Classification CASM
#'@export
TributaryConnectionCreator <- function(RECNetwork = CompleteSpatialNetwork, TributaryLabelList = TribLabelList, OutletReachNameLookUpTable = OutletReachNames){
 
  #For each independent catchment, find the distance along the reach to the confluence
  CatchmentTribLinkages <- lapply(seq_along(TributaryLabelList), function(CatchmentIndex) { 

    #Get the tributary labels for all REC reaches within the current independent catchment 
    CatchmentTribLabels <- TributaryLabelList[[CatchmentIndex]]
    
    #Lookup the catchment name based on the OutletReachNames look up table. Assume that only one reach in the OutletReachName look up table will match the reach numbers in the tributary.
    CatchmentName <- OutletReachNames$Name[OutletReachNames$nzsegment %in% CatchmentTribLabels$nzsgmnt]
    #print(CatchmentName)
    
    #Find all the unique tributary labels
    UniqueTribs <- unique(CatchmentTribLabels$Label)
    
    #for each tributary find the minimum LENGTHD attribute from the REC data, the REC reach immediately downstream of the tributary, and the tributary label of the REC reach that is immediately downstream. This builds a matrix of 4 numbers for each tributary, giving the minimum LENGTHD, the lowest nzsgmnt, the highest nzsgmnt below the tributary, and the label of the tributary below (i.e. the confluence name)
    ConfluenceTotalDistances <- sapply(UniqueTribs, function(TribLabel) {
      
      #Get the REC data for the current tributary
      ReachData <- RECNetwork[RECNetwork$nzsgmnt %in% CatchmentTribLabels$nzsgmnt[CatchmentTribLabels$Label == TribLabel],]
      
      #Find the smallest LENGTHD attribute for the tributary. Note the special case of reach 7260002 (Kaikokopu Stream) which doesn't have a LENGTHD attribute. Ideally we could simply ignore it, but it is a one-reach tributary (it is the outlet of a sub zone without point source or measurment sites within it) so it has to be used
      TribConnectionTotalDistance <- min(ReachData$LENGTHD)
      if (is.na(TribConnectionTotalDistance)) TribConnectionTotalDistance <- 0
      
      #Find which reach is the lowest in the tributary, based on the hdw_dst attribute
      LowestReach <- ReachData$nzsgmnt[which.max(ReachData$hdw_dst)] 
      
      #Find the reach immediately below the lowest reach
      ReachBelow <- RECNetwork$nzsgmnt[which(RECNetwork$FROM_NO == RECNetwork$TO_NODE[RECNetwork$nzsgmnt == LowestReach])]
      
      #Special case if it is the lowest tributary, as it is effectively the mainstem
      if(length(ReachBelow)==0) {
        ReachBelow <- NA
        TribBelow <- 1 }
      else {TribBelow <- CatchmentTribLabels$Label[CatchmentTribLabels$nzsgmnt == ReachBelow]}
      
      return(c(TribConnectionTotalDistance,LowestReach,ReachBelow,TribBelow))
    })
    
    #CASM needs the distance of a confluence above the previous confluence. So the LENGTHD of the bottom of the parent tributary needs to be subtracted from the LENGTHD of the current tributary. This is achieved by using the tributary values just created for each catchment.
    ConfluenceCorrectedDistances <- apply(ConfluenceTotalDistances, 2, function(x) {
      CorrectedDistance <- x[1] - ConfluenceTotalDistances[1,x[4]] 
    })
    
    #These confluence distances are added as a row to the rest of the tributary information
    AllDistances <- rbind(ConfluenceTotalDistances,ConfluenceCorrectedDistances)
    
    #Lastly, just the useful information is retained, and the labels are formatted to distinguish one catchment from another
    #I now want the tributary label, and the distance along the parent tributary, and the parent tributary label
    TributaryDetails <- data.frame("nzsgmnt"=AllDistances[2,],"Tributary Name" = paste0(CatchmentName,"-",seq(1:ncol(AllDistances))), "Confluence Stream" = paste0(CatchmentName,"-",AllDistances[4,]), "Confluence Location (km)" = round(AllDistances[5,]/1000,0), check.names = FALSE, stringsAsFactors = FALSE)
  })
  
  #Combine all the catchment information into a single data frame.
  AllCatchments <- do.call(rbind,CatchmentTribLinkages)
  rownames(AllCatchments) <- NULL
  return(AllCatchments)
}

#' A function to create a CASM node location table given an REC network with additional attributes of CASM tributary labels and CASM tributary distances
#'
#'This function generates a data frame of CASM Node names, CASM tributary, CASM tributary location 
#'
#'@param CASMRECNetwork An REC V2 network (either dataframe of spatial dataframe), with at least nzsgmnt, CASMTrib and CASMTrib_Loc attributes
#'@param CASMNodes A dataframe of node names and REC V2 reach number (i.e. nzsgmnt attribute) of the nodes for which the CASM table is to be prepared
#'@author Tim Kerr, \email{Tim.Kerr@@Rainfall.NZ}
#'@return A dataframe of CASM Node names, CASM tributary, CASM tributary location 
#'@keywords REC River Environment Classification CASM
#'@export
CASMNodeTablePreparer <- function(CASMRECNetwork=RECReachNetwork, NetworkLabelList = NetworkLabelList, TributaryConnectionTable = TributaryConnectionTable, CASMNodes=data.frame(NodeName = c("test","Manawatu at Teachers College"),nzsgmnt= c(7140020,7239110))){

  #Work through each catchment
  AllTribLocations <- lapply(NetworkLabelList, function(SingleCatchmentNeworkLabels) {
  
    #Get the catchment name
    CatchmentName <- OutletReachNames$Name[OutletReachNames$nzsegment %in% SingleCatchmentNeworkLabels$nzsgmnt]
    print(CatchmentName)
    
    #Find which CASMNodes are within the current catchment
    CatchmentNodes <- CASMNodes[(CASMNodes$nzsgmnt %in% SingleCatchmentNeworkLabels$nzsgmnt),]
    
    #Work through all the Nodes that are in this catchment
    if (nrow(CatchmentNodes) > 0) {
    #Now work through the nodes that are within the catchment, find the outlet reach, and then get the distance.
    TribLocations <- sapply(seq_along(CatchmentNodes$NodeName), function(NodeIndex){

      CASMNode <- CatchmentNodes[NodeIndex,]
      NodeNumber  <- SingleCatchmentNeworkLabels$Label[SingleCatchmentNeworkLabels$nzsgmnt == CASMNode$nzsgmnt]
      NodeTribName <- paste0(CatchmentName,"-",NodeNumber)
      
      #Look up the trib ID (prepended with the catchment name) of the reach of the current node and find the reach number (nzsgmnt attribute) of its confluence
      TribOutletReach <- TributaryConnectionTable$nzsgmnt[which(TributaryConnectionTable$`Tributary Name` == NodeTribName)]
      
      #Subtract the LENGTHD of the current reach from the LENGTHD of its tributary outlet reach
      LocationOnTrib <- CASMRECNetwork$LENGTHD[CASMRECNetwork$nzsgmnt == CASMNode$nzsgmnt] - CASMRECNetwork$LENGTHD[CASMRECNetwork$nzsgmnt == TribOutletReach]
      Result <- c(nzsgmnt=CASMNode$nzsgmnt,CASMNodeName=as.character(CASMNode$NodeName),TribName = NodeTribName,TribLocn = round(LocationOnTrib/1000,0))
      return(Result)   
       })
  } else {NULL}
    

  })

 #Turn the catchment-based list into a data frame
  CASMNodeTable <- data.frame(t(do.call(cbind,AllTribLocations)))
  #Convert the numbers into numbers
  CASMNodeTable$nzsgmnt <- as.numeric(levels(CASMNodeTable$nzsgmnt))[CASMNodeTable$nzsgmnt]
  CASMNodeTable$TribLocn <- as.numeric(levels(CASMNodeTable$TribLocn))[CASMNodeTable$TribLocn]
  return(CASMNodeTable)
}


#' A function to add labels to the REC network, based on the result of the network labeler and the OutletReachname look up table
#'
#'This function generates a data frame of CASM Node names, CASM tributary, CASM tributary location 
#'
#'@param NetworkLabels Ideally the output from the NetworkLabeler function. A list of dataframes (one for each independent river network) with the REC V2 "nzsgmnt" of confluence reaches and "Label" which is the assigned tributary number that the confluence is the start of.
#'@param OutletReachNamesLookUpTable A dataframe of names and REC V2 reach number (i.e. nzsgmnt attribute) for the lowest reach in each independent catchment.
#'@author Tim Kerr, \email{Tim.Kerr@@Rainfall.NZ}
#'@return A dataframe of reach numbers ("nzsgmnt") and tributary labels ("Label")
#'@keywords REC River Environment Classification CASM
#'@export
ReachLabeler <- function(NetworkLabels=NetworkLabelList,OutletReachNamesLookUpTable = OutletReachNames){
  PrefixedLabels <- lapply(NetworkLabels, function(SingleCatchmentNeworkLabels) {
    #Get the catchment name
    CatchmentName <- OutletReachNamesLookUpTable$Name[OutletReachNamesLookUpTable$nzsegment %in% SingleCatchmentNeworkLabels$nzsgmnt]
    
    #Prefix the catchment name on to the network labels
    PrefixedNetworkLabels <- paste0(CatchmentName,"-",SingleCatchmentNeworkLabels$Label)
    })
   
  PrefixedLabelVector <- unlist(PrefixedLabels)
  REC_nzsegment <- do.call(rbind,NetworkLabels)$nzsgmnt
  LabeledNetwork <- data.frame(nzsgmnt = REC_nzsegment, Prefixedlabel = PrefixedLabelVector, stringsAsFactors = FALSE)
  return(LabeledNetwork)
}
```

I also need a function to generate leaching rates based on PAW, irrigated land, irrigable land, climate and landuse data.
```{r}
LeachRateRasterCreator <- function(ClimateData=file.path(GISDataDirectory,ClimateShapeFileName),
                                   LanduseData=file.path(GISDataDirectory,SubZoneLanduseLUCShapeFileName),
                                   IrrigatedLandData=file.path(GISDataDirectory,IrrigatedLandShapeFileName),
                                   IrrigableLandData=file.path(GISDataDirectory,IrrigableLandShapeFileName),
                                   PAWData=file.path(GISDataDirectory,PAWShapeFileName),
                                   MPILeachRateData = file.path(DataDirectory,MPILeachRateLUTFile),
                                   LanduseToLanduseLUT = file.path(DataDirectory,LanduseToLanduseLUTFile)){
                                     #Load the lookup table that converts Horizon's Landuse names to the Landuse codes used by the MPI leaching-rate lookup table. 
                                     LanduseToLanduseLookUpTable <- read.csv(LanduseToLanduseLUT)
                                     
                                     #Load MPI lookup table of total nitrogen leaching rates based on climate, land use, PAW, irrigation, irrigable land
                                     MPILeachRateLookUpTable<- read.csv(MPILeachRateData)
                                     
                                     #concatenate all the predictor class values into a long string to provide a single column to look up.
                                     MPILeachRateLookUpTable$CombinedCriteria <- do.call(paste,MPILeachRateLookUpTable[1:5])
                                     
                                     #Load climate spatial data
                                     ClimateSpatial <- readOGR(ClimateData, stringsAsFactors = FALSE)
                                     #Make sure the class id is numeric
                                     ClimateSpatial@data$id <- as.numeric(ClimateSpatial@data$id)
                                     #Convert to raster, note the creation of a base raster, which all subsequent raster's align to
                                     RasterBase <- raster(resolution = 1000, ext = extent(ClimateSpatial), crs = proj4string(ClimateSpatial) )
                                     ClimateRaster <- rasterize(ClimateSpatial,RasterBase,"id")
                                     
                                     #Load the spatial data with the landuse, land use capability and submanagement zones alltogether
                                     SubZoneLanduseLUCSpatial <- readOGR(LanduseData,stringsAsFactors = FALSE)
                                     SubZoneLanduseLUCSpatial <- spTransform(SubZoneLanduseLUCSpatial,CRS("+init=epsg:2193") )
                                     
                                     #Determine the landuse code number needed to calculate MPI leaching rates
                                     SubZoneLanduseLUCSpatial@data$MPILanduseCode <- LanduseToLanduseLookUpTable$MPIClassNo[match(SubZoneLanduseLUCSpatial@data$RegiScLand,LanduseToLanduseLookUpTable$Horizons_Landuse_Name)]
                                     LanduseRaster <- rasterize(SubZoneLanduseLUCSpatial,RasterBase,"MPILanduseCode")
                                     
                                     #Load Irrigable land spatial data
                                     IrrigableLandSpatial <- readOGR(IrrigableLandData,stringsAsFactors = FALSE)
                                     IrrigableLandSpatial@data$Irrigable <- as.numeric(IrrigableLandSpatial@data$Irrigable)
                                     IrrigableRaster <- rasterize(IrrigableLandSpatial, RasterBase, rep(1,length(IrrigableLandSpatial)),background = 0)
                                     
                                     #Load irrigated land spatial data
                                     IrrigatedLandSpatial <- readOGR(IrrigatedLandData,stringsAsFactors = FALSE)
                                     IrrigatedLandSpatial@data$Irrigated <- as.numeric(IrrigatedLandSpatial@data$Irrigated)
                                     IrrigatedRaster <- rasterize(IrrigatedLandSpatial, RasterBase, rep(1,length(IrrigatedLandSpatial)),background = 0)
                                     
                                     #Load Plant Available Water (PAW) spatial data
                                     PAWSpatial <- readOGR(PAWData, stringsAsFactors = FALSE)
                                     #Convert PAW values to numbers (I don't know why they are characters)
                                     PAWSpatial$PAW_Cat2 <- as.numeric(PAWSpatial$PAW_Cat2)
                                     PAWRaster <- rasterize(PAWSpatial,RasterBase,"PAW_Cat2")
                                     
                                     #Create a raster brick with all the parameters needed to determine the MPI leach rate
                                     TotalRaster <- brick(ClimateRaster,LanduseRaster,PAWRaster,IrrigableRaster,IrrigatedRaster)
                                     names(TotalRaster) <- c("Climate","Landuse","PAW","Irrigable","Irrigated")
                                     
                                     # #Ton asked me to find which Horizon's predictor combinations didn't exist in the MPI look up table.
                                     # #Here is how to do that:
                                     # raspt <- rasterToPoints(TotalRaster)
                                     # PredictorCombinations <- as.data.frame(raspt[,c(3:7)])
                                     # UniquePredictorCombinations <- unique(PredictorCombinations)
                                     # names(UniquePredictorCombinations) <- names(MPILeachRateLookUpTable)[1:5]
                                     # library(dplyr)
                                     # bob <- anti_join(UniquePredictorCombinations, MPILeachRateLookUpTable[,1:5])
                                     # charlie <- bob[complete.cases(bob),]
                                     # write.table(charlie,file.path(DataDirectory,"MissingLeachRatePredictorCombinations.csv"),sep=",",quote=FALSE, row.names = FALSE)
                                     #Now calculate leach rates using the MPI lookup table. This is done by using the raster brick of the preditors. Each x,y cell of the brick is sampled (which gives a vector of 5 values) and this vector is converted into a long string. This is compared to the combined-class column in the MPI leaching rate look up table to get the Nitrogen loss.
                                     
                                     #Create a criteria raster

                                     
                                     #Use "calc" to work through each cell x,y cell of the raster brick
                                     LeachRateRaster <- calc(TotalRaster, function(x) {
                                       #i <<- i+1
                                       #if(i %in% 42153) browser()
                                       #Concatenate the predictor values of the current x,y, cell
                                       CriteriaToLookup <- paste(x,collapse=" ")
                                       #if(complete.cases(x)) browser()
                                       #lookup the current cell's predictor string in the look up table
                                       N_loss <- MPILeachRateLookUpTable$N_loss[MPILeachRateLookUpTable$CombinedCriteria %in% CriteriaToLookup]

                                       #Catch any missing values and make them NA
                                       if(length(N_loss) == 0) N_loss <- NA
                                       #if(is.na(N_loss)) N_loss <- NA
                                       
                                       return(N_loss)
                                     })
                                   }
```



Set directories and data file names
```{r}
#Set the project directory
#ProjectDirectory <- "C:\\Users\\Owner\\Documents\\Projects\\LWP\\Horizons"   #Tim Kerr's home Windows Desktop
ProjectDirectory <- "/home/tim/Desktop/Documents/Projects/LWP/Horizons"       #Tim Kerr's Ubuntu laptop

#Set the data directory
DataDirectory     <- file.path(ProjectDirectory, "Data")
#Set the GIS directory
GISDataDirectory  <- file.path(DataDirectory,"GIS")

#REC data is available from the MfE data service. See https://data.mfe.govt.nz/layer/51826-river-environment-classification-manawatu-2010/ and https://data.mfe.govt.nz/layer/51847-river-environment-classification-watershed-manawatu-2010/

REC_rivers <- "RECV2-Riverlines-Horizons"
REC_Catchments <- "RECV2-Watersheds-Horizons"

REC_MeanFlowFile <- "REC2MeanFlow.RData"  #This is an RData file

SubZones <-"Water_Management_Subzones_cleaned"

OutletReachNamesFile <- "OutletReachNames.csv" 

LanduseLUCShapefileName <- "Landuse_LUC Original"

SubZoneLanduseLUCShapeFileName <- "ZoneLanduseLUC/ZoneLanduseLUC.shp"

IrrigableLandShapeFileName <- "IrrigableLand/Irrigable-Horizons.shp"

IrrigatedLandShapeFileName <- "mfe-irrigated-land-area-2017-SHP/irrigated-land-area-2017-Manawatu.shp"

PAWShapeFileName <- "niFSL_fixedgeom/FSL_Horizons.shp"

ClimateShapeFileName <- "ClimateRegions/ClimateRegions-Horizon.shp"

MPILeachRateLUTFile <- "MPI_Baseline_N_losses_v2.csv"

MPIClassNameLUTFile <- "MPI_LookupNamesNLosses_v5.csv"

LanduseToLanduseLUTFile <- "LanduseToLanduseLookUpTable.csv"

LeachRateRasterFileName <- "LeachRateRaster.tif"

TargetZonesFileName <- "Target_subzones"
```

Chunk to find the total area of each Climate-PAW class within all the target Dairy-LUC combinations, and all the Irrigted Sheep and Beef-LUC combinations.
By Special request from Horizons.
```{r}


ClimateData=file.path(GISDataDirectory,ClimateShapeFileName)
                                   LanduseData=file.path(GISDataDirectory,SubZoneLanduseLUCShapeFileName)
                                   IrrigatedLandData=file.path(GISDataDirectory,IrrigatedLandShapeFileName)

                                   PAWData=file.path(GISDataDirectory,PAWShapeFileName)
                                   
                                   #Load climate spatial data
                                     ClimateSpatial <- readOGR(ClimateData, stringsAsFactors = FALSE)
                                     #Make sure the class id is numeric
                                     ClimateSpatial@data$id <- as.numeric(ClimateSpatial@data$id)
ClimateSpatial <- spTransform(ClimateSpatial,CRS("+init=epsg:2193") )
                                     
                                     #Load the spatial data with the landuse, land use capability and submanagement zones alltogether
                                     SubZoneLanduseLUCSpatial <- readOGR(LanduseData,stringsAsFactors = FALSE)
                                     SubZoneLanduseLUCSpatial <- spTransform(SubZoneLanduseLUCSpatial,CRS("+init=epsg:2193") )
                                     
                                     #Load irrigated land spatial data
                                     IrrigatedLandSpatial <- readOGR(IrrigatedLandData,stringsAsFactors = FALSE)
                                     IrrigatedLandSpatial@data$Irrigated <- as.numeric(IrrigatedLandSpatial@data$Irrigated)
                                     IrrigatedLandSpatial <- spTransform(IrrigatedLandSpatial,CRS("+init=epsg:2193") )

                                     
                                     #Load Plant Available Water (PAW) spatial data
                                     PAWSpatial <- readOGR(PAWData, stringsAsFactors = FALSE)
                                     #Convert PAW values to numbers (I don't know why they are characters)
                                     PAWSpatial$PAW_Cat2 <- as.numeric(PAWSpatial$PAW_Cat2)
PAWSpatial <- spTransform(PAWSpatial,CRS("+init=epsg:2193") )


TargetZones <- readOGR(file.path(GISDataDirectory,TargetZonesFileName),TargetZonesFileName, stringsAsFactors = FALSE)
TargetZones <- spTransform(TargetZones,CRS("+init=epsg:2193") )

#Select the target zones from the Land use data
TargetZoneLanduseLUC <- SubZoneLanduseLUCSpatial[which(SubZoneLanduseLUCSpatial$Zone_Code %in% TargetZones$Zone_Code),]

#only interested in Dairy
TargetZoneLanduseLUC_Dairy<- TargetZoneLanduseLUC[which(TargetZoneLanduseLUC$RegiScLand =="Dairy"),]

#only interested in irrigated sheep and beef, so select the sheep and beef
TargetZoneLanduseLUC_SheepAndBeef <- TargetZoneLanduseLUC[which(TargetZoneLanduseLUC$RegiScLand == "Sheep and/or Beef"),]
#Intersect with irrigated
TargetZoneLanduseLUC_SheepAndBeef_Irrigated <- intersect(TargetZoneLanduseLUC_SheepAndBeef,IrrigatedLandSpatial)
#Select just the Irrigated
TargetZoneLanduseLUC_SheepAndBeef_Irrigated <- TargetZoneLanduseLUC_SheepAndBeef_Irrigated[which(TargetZoneLanduseLUC_SheepAndBeef_Irrigated$Irrigated == 1),]

#Interesect the target zones with Climate
TargetZoneLanduseLUC_Dairy_Climate <- intersect(TargetZoneLanduseLUC_Dairy,ClimateSpatial)

#And then intersect with PAW
TargetZoneLanduseLUC_Dairy_Climate_PAW <- intersect(TargetZoneLanduseLUC_Dairy_Climate,PAWSpatial)
#and add areas
TargetZoneLanduseLUC_Dairy_Climate_PAW$area <- area(TargetZoneLanduseLUC_Dairy_Climate_PAW)
#just get the columns we want
TargetZoneLanduseLUC_Dairy_Climate_PAW <- TargetZoneLanduseLUC_Dairy_Climate_PAW[,c("LUC_CLASS","Zone_Code","Class","id","PAW_Cat2","area")]

#Now sum the areas for the unique combinations of everything.
#This solution is from https://stackoverflow.com/questions/27137174/sum-a-rows-within-a-column-for-each-unique-combination-r
library(data.table)
#Do the summing
TargetZoneLanduseLUC_Dairy_Climate_PAW_summedAreas <- setDT(TargetZoneLanduseLUC_Dairy_Climate_PAW@data)[, Sum := round(sum(area)/10000,1), by = .(LUC_CLASS,Zone_Code,Class,PAW_Cat2)][]

#Get the unique values
TargetZoneLanduseLUC_Dairy_Climate_PAW_summedAreas <- unique(TargetZoneLanduseLUC_Dairy_Climate_PAW_summedAreas[,-6])

#Rename
names(TargetZoneLanduseLUC_Dairy_Climate_PAW_summedAreas) <- c("LUC","Zone","Climate","Climate No.","PAW","Area (Ha)")

#Add the landuse
DairyData$Landuse <- "Dairy"


#Repeat for Irrigated Sheep and Beef
TargetZoneLanduseLUC_SheepAndBeef_Irrigated_Climate<- intersect(TargetZoneLanduseLUC_SheepAndBeef_Irrigated,ClimateSpatial)
TargetZoneLanduseLUC_SheepAndBeef_Irrigated_Climate_PAW <- intersect(TargetZoneLanduseLUC_SheepAndBeef_Irrigated_Climate,PAWSpatial)
TargetZoneLanduseLUC_SheepAndBeef_Irrigated_Climate_PAW$area <- area(TargetZoneLanduseLUC_SheepAndBeef_Irrigated_Climate_PAW)
TargetZoneLanduseLUC_SheepAndBeef_Irrigated_Climate_PAW <- TargetZoneLanduseLUC_SheepAndBeef_Irrigated_Climate_PAW[,c("LUC_CLASS","Zone_Code","Class","id","PAW_Cat2","area")]


TargetZoneLanduseLUC_SheepAndBeef_Irrigated_Climate_PAW_summedAreas <- setDT(TargetZoneLanduseLUC_SheepAndBeef_Irrigated_Climate_PAW@data)[, Sum := round(sum(area)/10000,1), by = .(LUC_CLASS,Zone_Code,Class,PAW_Cat2)][]

TargetZoneLanduseLUC_SheepAndBeef_Irrigated_Climate_PAW_summedAreas <- unique(TargetZoneLanduseLUC_SheepAndBeef_Irrigated_Climate_PAW_summedAreas[,-6])

names(TargetZoneLanduseLUC_SheepAndBeef_Irrigated_Climate_PAW_summedAreas) <- c("LUC","Zone","Climate","Climate No.","PAW","Area (Ha)")


#Add the landuse
SheepAndBeefIrrigatedData$Landuse <- "SheepAndBeef_Irrigated"

#Combine the Dairy and the SheepAndBeef data
CombinedData <- rbind(DairyData,SheepAndBeefIrrigatedData)
#Reorder the columns
CombinedData <- CombinedData[,c("Zone","Landuse","LUC","Climate","PAW","Area (Ha)")]

#Re-order the rows
CombinedData <- CombinedData[order(CombinedData$Zone, CombinedData$Landuse, CombinedData$LUC, CombinedData$Climate, CombinedData$PAW),]

#Write to a file
write.table(CombinedData, file.path(DataDirectory,"TargetZone_Dairy_and_Irrigated_Sheep_And_Beef_Categorised_Areas.csv"),sep=",",row.names=FALSE,quote=FALSE)
```



load data
```{r}
#REC data has been soured from the NIWA website. It has cut down versions of the attribute names, e.g. nzsegment is nzsgmnt. Keep an eye on this when comparing to other data sources that may have the full RECV2 attribute names.
RECReachNetwork <- readOGR(dsn =file.path(GISDataDirectory,REC_rivers),
                           layer = "RECV2-Riverlines-Horizons")
RECReachNetwork <- spTransform(RECReachNetwork,CRS("+init=epsg:2193") )

#RECWatersheds <- readOGR(dsn = file.path(GISDataDirectory,REC_Catchments),
#                         layer = "RECV2-Watersheds-Horizons")
#RECWatersheds <- spTransform(RECWatersheds,CRS("+init=epsg:2193") )

#Load the mean flow data for the REC V2. This is provided in an rdata file which contains the data frame REC2MeanFlow, with three columns, "nzsegment","QMean", and "us_catarea"
load(file.path(DataDirectory, REC_MeanFlowFile))

#Load the Horizon total nitorigen load measurement sites, previously prepared by Caroline Fraser and called "HZLoads
load(file.path(DataDirectory,"N_ExpCoeff_Est_HZ_Feb20.rdata"))
#Select just the TN sites
MeasurementSites <- HZLoads[which(HZLoads$npID=="TN"),]

#Calculate loads as t/y
MeasurementSites$load <- round(MeasurementSites$ExpCoef * MeasurementSites$CATCHAREA / 10000,2)
MeasurementSites$load_Uci <- round(MeasurementSites$ExpCoef_Uci_ * MeasurementSites$CATCHAREA / 10000,2)
MeasurementSites$load_Lci <- round(MeasurementSites$ExpCoef_Lci_ * MeasurementSites$CATCHAREA / 10000,2)

#Create a spatial points object set to NZTM
MeasurementSitesSpatial <-SpatialPointsDataFrame(coords = MeasurementSites[,c("NZTM.X","NZTM.Y")],
                                               data = MeasurementSites[,1:13],
                                               proj4string = CRS("+init=epsg:2193"))



#Load the point sources of nitrogen, previously prepared by Caroline Fraser. Unfortunately they don't have nzsgmnt data. notethat an erro was found for the NZTM.X position of the Fonterra at Pahiatua site. Originally it was 1859554.9 but it should be 1839554.9. This has been corrected on the LWP sharepoint version of the 20200201_HorizonsRiverCriteria.xlsx file, and the Tim Kerr version of the PointSourcesSummaryPC2_YE2012_04.csv file.
PointSourceSites <- read.csv(file.path(DataDirectory,"PointSourcesSummaryPC2_YE2012_04.csv"))

#Create a spatial points object set to NZTM
PointSourceSitesSpatial <-SpatialPointsDataFrame(coords = PointSourceSites[,c("NZTM.X","NZTM.Y")],
                                               data = PointSourceSites[,1:5],
                                               proj4string = CRS("+init=epsg:2193"))

#Load the subzone polygons
SubZonePolygons <- readOGR(dsn =file.path(GISDataDirectory,SubZones),
                           layer = SubZones)
SubZonePolygons <- spTransform(SubZonePolygons,CRS("+init=epsg:2193") )

#Load the network outlet reach names lookup table. This has been manually prepared, and may need editing if the network changes to include outlet reaches not yet included in this file
OutletReachNames <- read.csv(file.path(DataDirectory,OutletReachNamesFile), stringsAsFactors = FALSE)

#Load the spatial data with the landuse, land use capability and submanagement zones alltogether
#LanduseLUCSpatial <- readOGR(dsn =file.path(GISDataDirectory,LanduseLUCShapefileName),
#                           layer = LanduseLUCShapefileName)
#LanduseLUCSpatial <- spTransform(LanduseLUCSpatial,CRS("+init=epsg:2193") )
SubZoneLanduseLUCSpatial <- readOGR(file.path(GISDataDirectory,SubZoneLanduseLUCShapeFileName))
SubZoneLanduseLUCSpatial <- spTransform(SubZoneLanduseLUCSpatial,CRS("+init=epsg:2193") )

#Load the leachingrate data if it exists
LeachRate <- raster(file.path(GISDataDirectory,LeachRateRasterFileName))

#**********************************************************
##If the leach rate raster file is missing or needs to be re-created then use the following:
##LeachRate <- LeachRateRasterCreator()
##And save it for nexttime
#writeRaster(LeachRate,file.path(GISDataDirectory,LeachRateRasterFileName),overwrite=TRUE)
#******************************************************************
```
I need to analyse each management sub zone to determine how much area (in hectares) each landuse-LUC combination takes up.
Unfortunately there is a decrepancy between provided data for the sub management zones. Upon query to Horizons (See email exchange between Ton Snelder and Stephen Collins- Horizons on 17th Feb 2020), the zones within the "Water_Management_Subzones" ESRI shapefile trumps those within the "Landuse_LUC Original". So the land use and LUC is extracted from one file, then intersected with the other.This proved to be problematic because both files had topology errors, primarily small circles in the boundaries, so the files had to be "cleaned". This proved to be most effectively done in QGIS. They were then intersected in QGIS, and then aggregated by RegiScLand, LUC_CLASS and Zone_Code in R (see below) before being saved as a file so that the painfull process doesn't have to be repeated.
```{r}

#Intersect the Landuse and LUC with the sub-management zones
#SubZoneLanduseLUCSpatial <- intersect(LanduseLUCSpatial,SubZonePolygons)

#Aggregate on sub_zone, Landuse and LUC and save for later
#SubZoneLanduseLUCSpatial <- aggregate(SubZoneLanduseLUCSpatial,by=c("RegiScLand","LUC_CLASS","Zone_Code"))
#writeOGR(bob,GISDataDirectory,ZoneLanduseLUC,driver='ESRI Shapefile')

#Find the area of each Landuse-LUC combination for each sub-zone
SubZoneLanduseLUCSpatial$hectares <- round(raster::area(SubZoneLanduseLUCSpatial) / 10000,1)

#Create a new combined name
SubZoneLanduseLUCSpatial$CombinedClassName <- with(SubZoneLanduseLUCSpatial@data, paste0(Zone_Code,"-",RegiScLand,"-",LUC_CLASS))

##Get the average leach rate for each polygon THIS TAKES ABOUT 75 MINUTES
#leachvalues <- raster::extract(LeachRate, SubZoneLanduseLUCSpatial, fun = mean, na.rm=TRUE, sp=TRUE)
```



Get the "nzsgmnt" attributes of the lowest reach in each of the management subzones
```{r}
SubZoneOfEachReach <- RECReachNetwork %over% SubZonePolygons #Note this takes about a minute to do
RECReachNetwork$SubZoneCode <- SubZoneOfEachReach$Zone_Code

#Work through each management zone to find the reach with the greatest distance to the headwater (the hdw_dst attribute). . I tried doing this based on the least largest area (the CUM_ARE attribute) but there were some zero values, I also tried distance to the sea (the LENGTHD attribute, but near the coast I was getting small reaches that were not the main river channel, but were closer to the sea)
ManagementSubZoneOutletReaches <- lapply(seq_along(SubZonePolygons$Zone_Code), function(SingleSubZoneIndex){
  #browser()
  CurrentSubZone <- SubZonePolygons$Zone_Code[SingleSubZoneIndex]
  CurrentSubZoneReaches <- RECReachNetwork[RECReachNetwork$SubZoneCode == CurrentSubZone,]
  OutletReach <- CurrentSubZoneReaches$nzsgmnt[which.max(CurrentSubZoneReaches$hdw_dst)]
  return(data.frame(SubZone = CurrentSubZone,nzsgmnt = OutletReach))
})
#Convert the list into a dataframe
ManagementSubZoneOutletReachesDF <- do.call(rbind,ManagementSubZoneOutletReaches)
```


From the load sites, point source sites, and water management subzones outlets, create the required network
```{r}
AllPoints <- c(MeasurementSites$nzsegment, PointSourceSites$nzsegment, ManagementSubZoneOutletReachesDF$nzsgmnt)
LoadNetwork <- lapply(AllPoints, function(x) {DownstreamReachFinder(RECNetwork = RECReachNetwork, SourceReach = x)} )
CompleteNetwork <- unlist(LoadNetwork)
CompleteNetwork <- CompleteNetwork[!duplicated(CompleteNetwork)]

CompleteSpatialNetwork <- RECReachNetwork[RECReachNetwork$nzsgmnt %in% CompleteNetwork,]
```

Then create a tributary table ready for CASM
```{r}

NetworkLabelList <- NetworkLabeler(CompleteSpatialNetwork)


#Add the tributary labels to the network
SegmentToLabelLookUpTable <- do.call(rbind,NetworkLabelList)
CompleteSpatialNetwork@data$Label <- SegmentToLabelLookUpTable$Label[match(CompleteSpatialNetwork@data$nzsgmnt,SegmentToLabelLookUpTable$nzsgmnt)]
#Add the prefixed labels to the network
SegmentToPrefixedLabelLookUpTable <- ReachLabeler(NetworkLabelList, OutletReachNames)
CompleteSpatialNetwork@data$PrefixedLabel <- SegmentToPrefixedLabelLookUpTable$Prefixedlabel[match(CompleteSpatialNetwork@data$nzsgmnt,SegmentToPrefixedLabelLookUpTable$nzsgmnt)]

#Add the 
#Save the network as a spatial file
writeOGR(CompleteSpatialNetwork, file.path(GISDataDirectory), "CASM-StreamNetwork", driver="ESRI Shapefile",overwrite_layer=TRUE)

TributaryConnectionTable <- TributaryConnectionCreator(RECNetwork = CompleteSpatialNetwork, TributaryLabelList = NetworkLabelList)
```

Then create a point source table ready for CASM,
a measurementsite table ready for CASM,
and a diffuse inputs table ready for CASM
```{r}
#Create a dataframe of just the nzsegment number and the site name
PointSourceNodes <- PointSourceSites[,c("Site.Name","nzsegment")]

#Standardise the column names so that it matches the expected format in the CASMNodeTablePreparer() function
names(PointSourceNodes) <- c("NodeName","nzsgmnt")

#Prepare the CASM table with the bonus nzsgmnt column
PointSourceTable <- CASMNodeTablePreparer(CASMRECNetwork = CompleteSpatialNetwork, NetworkLabelList = NetworkLabelList, TributaryConnectionTable = TributaryConnectionTable,CASMNodes = PointSourceNodes )

#rename the columns to match the CASM requirements
names(PointSourceTable) <- c("nzsgmnt","Point Source Name","Receiving Stream","Location (km)")
 
#Need to add the point source load to the table
PointSourceTable$"Annual Load (kg/yr)" <- round(PointSourceSites$TN.kgpy[match(PointSourceTable$nzsgmnt,PointSourceSites$nzsegment)],0)
```



#Repeat for the measurement sites
```{r}
MeasurementSiteNodes <- MeasurementSites[,c("sID","nzsegment")]
names(MeasurementSiteNodes) <- c("NodeName","nzsgmnt")
MeasurementSiteTable <- CASMNodeTablePreparer(CASMRECNetwork = CompleteSpatialNetwork, NetworkLabelList = NetworkLabelList, TributaryConnectionTable = TributaryConnectionTable,CASMNodes= MeasurementSiteNodes)

#rename the columns to match the CASM conventions
names(MeasurementSiteTable) <- c("nzsgmnt","Site Name or No","Target Stream","Downstream Location (km)")

#Add the mean annual flow to the table
MeasurementSiteTable$"Mean flow (m3/s)" <- round(REC2MeanFlow$QMean[match(MeasurementSiteTable$nzsgmnt, REC2MeanFlow$nzsegment)],1)

#Add a variety of other fields from the Measurement Site data
MeasurementSiteTable$'Load (tpy)' <- round(MeasurementSites$load[match(MeasurementSiteTable$"Site Name or No", MeasurementSites$sID)],1)
MeasurementSiteTable$'Load Lci (tpy)' <- round(MeasurementSites$load_Lci[match(MeasurementSiteTable$"Site Name or No", MeasurementSites$sID)],1)
MeasurementSiteTable$'Load Uci (tpy)' <- round(MeasurementSites$load_Uci[match(MeasurementSiteTable$"Site Name or No", MeasurementSites$sID)],1)
```

#Repeat for diffuse inputs. This is a special case, because once the points have been found, they need to be joined with all the different landuse/LUC options
```{r}
#Start with all the diffuse source input nodes. These are the sub-management zone outlets
DiffuseInputsSiteNodes <- ManagementSubZoneOutletReachesDF
names(DiffuseInputsSiteNodes) <- c("NodeName","nzsgmnt")

#Build up the table of tributary names and locations associated with the diffuse source input sites
DiffuseInputsSiteTable <- CASMNodeTablePreparer(CASMRECNetwork = CompleteSpatialNetwork, NetworkLabelList = NetworkLabelList, TributaryConnectionTable = TributaryConnectionTable,CASMNodes= DiffuseInputsSiteNodes)

#Now create a bigger version, with a row for each of the different landuse/LUC combinations within each sub-management zone
DiffuseInputsSiteExtendedTable <- SubZoneLanduseLUCSpatial@data

#Add the locations that we have just previously determined
DiffuseInputsSiteExtendedTable[,c("TribLocn","TribName")] <- DiffuseInputsSiteTable[match(SubZoneLanduseLUCSpatial@data$Zone_Code, DiffuseInputsSiteTable$CASMNodeName),c("TribLocn","TribName")]

#Add the leach rates
DiffuseInputsSiteExtendedTable$"LeachRates" <-round( leachvalues@data$LeachRateRaster[match(DiffuseInputsSiteExtendedTable$CombinedClassName,leachvalues@data$CombinedClassName)],1)

#I now need to adjust the locations of all the different landuse/LUC options for a single diffuse source point so that they are not all on exactly the same spot.
#Work along each sub management zone, get all the landuse/LUC classes, and increment the locations by 0.1 km
DiffuseInputsSiteExtendedTable$AdjustedTriblocn <- DiffuseInputsSiteExtendedTable$TribLocn
UniqueSubZones <- unique(DiffuseInputsSiteExtendedTable$Zone_Code)
for(SubZoneIndex in seq_along(UniqueSubZones)) {
  #get the subzone of interest
  SubZone <- UniqueSubZones[SubZoneIndex]
  
  #Get all the landuse/LUC classes in the subzone
  RowsOfInterest <- which(DiffuseInputsSiteExtendedTable$Zone_Code == SubZone)
  DiffuseInputsSiteExtendedTable$AdjustedTriblocn[RowsOfInterest] <- DiffuseInputsSiteExtendedTable$TribLocn[RowsOfInterest] + seq(0,by = 0.01, length.out = length(RowsOfInterest))
}
#rename the columns to match the CASM conventions
names(DiffuseInputsSiteExtendedTable) <- c("Landuse","LUC","Zone_Code","MPILanduseClass","Land Area (ha)","Node Name","Original location (km)", "Receiving Stream","Export Coeff (kg/ha/yr)","Discharge Location (km)")

```


Create a plot
```{r}
# plot(SubZonePolygons, col = "transparent")
# plot(CompleteSpatialNetwork, col = "blue", add=TRUE)
# plot(PointSourceSitesSpatial, add=TRUE, col = "red")
#plot(MeasurementSitesSpatial, add=TRUE, col = "black")
```
Or another plot
```{r}
# #Put all the spatial data in a list for simplicity
# SpatialData <- list(MeasurementSites=MeasurementSitesSpatial, PointSourceSites=PointSourceSitesSpatial,
#                     SubZones=SubZonePolygons,RiverNetwork=CompleteSpatialNetwork)
# #Get the extents of the area in lat lon
# MapExtentLatLon <- extent(projectExtent(SubZonePolygons, crs('+init=epsg:4326')))
# #Expand the extents to provide extents for the topographical map to download
# MapExtents <- MapExtentLatLon + 0.005
# LINZAPIToken <- "85df745fa5d446fea241dd5ae40add85"
# #And use those extents to get the Topo250 data. Note that I seem to need to download the data first, then load it into R.
# download.file(paste0("https://data.linz.govt.nz/services;key=",LINZAPIToken,"/wms?service=WMS&version=1.1.1&request=GetMap&layers=layer-50798&format=image/geotiff&width=1456&height=1600&bbox=",MapExtents@xmin,",",MapExtents@ymin,",",MapExtents@xmax,",",MapExtents@ymax),destfile <- file.path(GISDataDirectory,"TopoNZ.tif"))
# Topo250Map <- stack(file.path(GISDataDirectory,"TopoNZ.tif"))
# #Need to set NA values to 0
# values(Topo250Map)[is.na(values(Topo250Map))] <- 0
# 
# #Reproject the other spatial data to the maps projection ready for plotting
# reprojected.data <- lapply(SpatialData, spTransform,Topo250Map@crs)
# list2env(reprojected.data,env=.GlobalEnv)
# 
# {
# plotRGB(Topo250Map,colNA="white")
# plot(SubZones, add=TRUE)
# points(MeasurementSites,pch=20)
# points(PointSourceSites, pch = 8, col = "dark green")
# lines(RiverNetwork, col = "blue")
# legend("topleft",bty="n",legend=c("SubZones","Measurement \nSites","Point Source Sites","River \nNetwork"),pch=c(0,20,8,NA),pt.cex=c(1.3,1,1,NA),merge=TRUE,lty=c(-1,-1,-1,1),col=c("black","black","dark green","blue"))
# north.arrow(xb=par("usr")[1] + 0.0015,yb=par("usr")[3]+0.0009, len = 0.0002)
# map.scale(xc=par("usr")[1] + 0.0015,yc=-42.89077,len=1/(1110.91/2.5), units= "metres", ndivs=1, subdiv = 250)
# }
# 
# #Generate a plot file
# dev.copy(png,file=file.path(DataDirectory,
#                             "OverviewMap.png")
#          ,width=19,height=28,units="cm",res=600,family="Arial",pointsize=8)
#invisible(dev.off())
```
Or another plot
```{r}
#Reproject the other spatial data to the maps projection ready for plotting
SpatialData <- list(MeasurementSites=MeasurementSitesSpatial, PointSourceSites=PointSourceSitesSpatial,
                    SubZones=SubZonePolygons,RiverNetwork=CompleteSpatialNetwork)
reprojected.data.WGS84 <- lapply(SpatialData, spTransform,CRS("+init=epsg:4326"))


map <- leaflet::leaflet() %>% 
  leaflet::addProviderTiles(providers$OpenStreetMap) %>%
  setView(lng=175.5,lat=-40.0,zoom=8) %>% 
  addPolygons(data = reprojected.data.WGS84$SubZones, color = "black", weight = 3, fillColor = "transparent", label = ~htmlEscape(Zone_Code)) %>%
  addCircleMarkers(data = reprojected.data.WGS84$MeasurementSites, color = "red",label = ~htmlEscape(sID)) %>%
  addCircleMarkers(data = reprojected.data.WGS84$PointSourceSites, color = "black", label = ~htmlEscape(Site.Name)) %>%
  addPolylines(data = reprojected.data.WGS84$RiverNetwork, color= "blue", label = ~htmlEscape(PrefixedLabel))
map

#save the mapdata as an R file so that it can be used in an RShinyApp
saveRDS(reprojected.data.WGS84,file.path(ProjectDirectory,"R/CASM-PrePostProcessor/ShinyApp/Data","SpatialData.RDS"))
```


The tributary connection table needs to be converted to an Excel Spreadsheet.


I need to create an excel table of CASM-Nodes, CASM-Reach-Names, CASM-Reach-Locations, CASM-Reach-Areas, CASM-Reach-Exp.Coeff
```{r}


Out <- createWorkbook()

addWorksheet(Out, "River Network")

writeData(Out, sheet = "River Network", x = TributaryConnectionTable[c("Tributary Name","Confluence Stream","Confluence Location (km)")])

addWorksheet(Out, "Point Source")

writeData(Out, sheet = "Point Source", x = PointSourceTable[,-1])

addWorksheet(Out, "Water Quality Stations")

writeData(Out, sheet = "Water Quality Stations", x = MeasurementSiteTable[,-1])

addWorksheet(Out, "Diffuse Inputs")


writeData(Out, sheet = "Diffuse Inputs", x = DiffuseInputsSiteExtendedTable[,c("Node Name","Receiving Stream","Discharge Location (km)","Land Area (ha)","Export Coeff (kg/ha/yr)")])

saveWorkbook(Out, file.path(DataDirectory,"CASM-Inputs.xlsx"), overwrite = T)
```



